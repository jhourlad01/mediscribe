# MediScribe - Local AI Medical Transcription App

Local medical transcription application using Whisper AI, with Next.js frontend and Node.js + Express backend.

## Architecture

```
/app
â”œâ”€â”€ web/              # Next.js frontend (port 3000)
â”œâ”€â”€ api/              # Node.js + Express backend (port 5000)
â””â”€â”€ ai/               # Python AI scripts (Whisper transcription)
```

## Tech Stack

- **Frontend**: Next.js 15, TypeScript, Tailwind CSS, Material-UI
- **Backend**: Node.js, Express, MongoDB Atlas
- **AI**: OpenAI Whisper (local transcription with word-level timestamps)

## Quick Start

### Prerequisites

- Node.js 20+
- Python 3.8+
- **ffmpeg** (REQUIRED for audio): `winget install ffmpeg` or download from https://ffmpeg.org
- MongoDB Atlas account

### 1. Backend API Setup

```bash
cd api
npm install
cp env.example .env
# Edit .env with your MongoDB URI
npm run dev
```

### 2. Frontend Setup

```bash
cd web
npm install
cp env.example .env.local
npm run dev
```

### 3. AI Setup

```bash
cd ai
pip install -r requirements.txt
```

## Environment Variables

### Backend (.env)
```
PORT=5000
MONGO_URI=mongodb+srv://<user>:<password>@cluster0.mongodb.net/mediscribe
WHISPER_MODEL=base
WHISPER_LANGUAGE=en
FRONTEND_URL=http://localhost:3000
```

### Frontend (.env.local)
```
NEXT_PUBLIC_API_URL=http://localhost:5000
```

## User Workflow

1. **Patient List** - Home page displays all patients with search functionality
2. **Create Patient** - Add new patient with basic information
3. **Patient Details** - View patient info, summary, and transcriptions
4. **Upload Audio** - Upload audio files for transcription
5. **Record Audio** - Record audio directly in browser
6. **AI Processing** - Whisper transcribes â†’ Ollama validates/corrects
7. **Edit Transcript** - Doctor reviews and edits with access to original versions
8. **Save Changes** - Edits are tracked with history

[ðŸ“– **Detailed Workflow Documentation â†’** WORKFLOW.md](./WORKFLOW.md)

## Communication Flow

```
User Browser (3000) 
  â†“ HTTP
Express API (5000)
  â†“ subprocess
  â”œâ†’ Python Whisper (transcribe with word timestamps)
  â””â†’ MongoDB Atlas (store)
```

## Features

âœ… **Patient Management**
- Create, view, search patients
- Patient profiles with demographics
- Medical record numbers

âœ… **Audio Capture**
- Upload audio files (mp3, wav, m4a, ogg, flac)
- In-browser audio recording
- File size and format validation

âœ… **AI Transcription**
- Whisper AI transcription
- Ollama validation and correction
- Medical terminology optimization

âœ… **Transcript Management**
- View original, validated, and edited versions
- Edit history tracking
- Status indicators

âœ… **Modern UI**
- Material-UI components
- Responsive design
- Real-time updates
- Progress indicators

## API Endpoints

### Patients
- `GET /api/patients` - Get all patients
- `GET /api/patients/:id` - Get patient details
- `POST /api/patients` - Create patient
- `PUT /api/patients/:id` - Update patient
- `DELETE /api/patients/:id` - Delete patient
- `GET /api/patients/:id/transcripts` - Get patient transcripts

### Transcripts
- `POST /api/upload` - Upload audio and transcribe
- `GET /api/transcripts` - Get all transcripts
- `GET /api/transcripts/:id` - Get transcript
- `PUT /api/transcripts/:id` - Update transcript
- `DELETE /api/transcripts/:id` - Delete transcript
- `GET /api/health` - Health check

## Development

```bash
# Start all services in separate terminals

# Terminal 1: Backend
cd api && npm run dev

# Terminal 2: Frontend
cd web && npm run dev

# Terminal 3: Redis (if local)
redis-server database/redis/redis.conf

# Terminal 4: Ollama
ollama serve
```

## Project Structure

```
app/
â”œâ”€â”€ web/                      # Next.js Frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/             # App Router pages
â”‚   â”‚   â”‚   â”œâ”€â”€ page.tsx     # Patient list (home)
â”‚   â”‚   â”‚   â””â”€â”€ patients/[id]/page.tsx  # Patient details
â”‚   â”‚   â”œâ”€â”€ components/      # React components
â”‚   â”‚   â”‚   â”œâ”€â”€ AudioUploadDialog.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ AudioRecorder.tsx
â”‚   â”‚   â”‚   â””â”€â”€ TranscriptEditor.tsx
â”‚   â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”‚   â””â”€â”€ api.ts       # API client
â”‚   â”‚   â””â”€â”€ theme/           # MUI theme
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ api/                     # Express Backend
â”‚   â”œâ”€â”€ controllers/
â”‚   â”‚   â”œâ”€â”€ transcriptionController.js
â”‚   â”‚   â””â”€â”€ validationController.js
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ Patient.js
â”‚   â”‚   â””â”€â”€ Transcript.js
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ patients.js
â”‚   â”‚   â”œâ”€â”€ transcripts.js
â”‚   â”‚   â””â”€â”€ upload.js
â”‚   â”œâ”€â”€ server.js
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ ai/                      # Python AI
â”‚   â”œâ”€â”€ transcribe.py       # Whisper integration
â”‚   â”œâ”€â”€ validate.py         # Ollama integration
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ prompts/            # AI prompts
â”‚
â””â”€â”€ database/
    â””â”€â”€ redis/              # Redis config
```

## Notes

- Backend orchestrates AI and DB operations
- Frontend never calls AI directly
- Whisper runs locally via Python subprocess
- Ollama runs locally via CLI
- MongoDB Atlas stores permanent data
- Redis handles caching and job queues
- All transcriptions linked to patients
- Edit history preserved for audit trail

